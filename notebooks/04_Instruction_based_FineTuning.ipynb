{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15dbd3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Available: 5.61 GB\n",
      "GPU Memory Allocated: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Restart your kernel first, then run this cell\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear all CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Check available memory\n",
    "print(f\"GPU Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966f3e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 2.1.3\n",
      "matplotlib version: 3.10.8\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.9.1\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.19.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9762eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        text_data = response.text\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instructions/instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d96032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n",
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])\n",
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c59664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5fb756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49a9739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b35de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405c714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e85d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry[\"output\"]}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b622817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a57307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device='cuda'):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65180479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9989b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device='cuda'):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "        inputs = torch.tensor(padded[:-1]) # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a297cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c14e6b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cross Entropy loss function ignores the index -100\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8829ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eeedd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers=0\n",
    "batch_size=1\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7af045b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([1, 40]) torch.Size([1, 40])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 82]) torch.Size([1, 82])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 83]) torch.Size([1, 83])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 74]) torch.Size([1, 74])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 79]) torch.Size([1, 79])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 72]) torch.Size([1, 72])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 87]) torch.Size([1, 87])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 91]) torch.Size([1, 91])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 42]) torch.Size([1, 42])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 75]) torch.Size([1, 75])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 72]) torch.Size([1, 72])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 77]) torch.Size([1, 77])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 76]) torch.Size([1, 76])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 91]) torch.Size([1, 91])\n",
      "torch.Size([1, 77]) torch.Size([1, 77])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 41]) torch.Size([1, 41])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 42]) torch.Size([1, 42])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 70]) torch.Size([1, 70])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 83]) torch.Size([1, 83])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 70]) torch.Size([1, 70])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 83]) torch.Size([1, 83])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 75]) torch.Size([1, 75])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 80]) torch.Size([1, 80])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 83]) torch.Size([1, 83])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 74]) torch.Size([1, 74])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 73]) torch.Size([1, 73])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 70]) torch.Size([1, 70])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 72]) torch.Size([1, 72])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 70]) torch.Size([1, 70])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 75]) torch.Size([1, 75])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 42]) torch.Size([1, 42])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 70]) torch.Size([1, 70])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 77]) torch.Size([1, 77])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 80]) torch.Size([1, 80])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 42]) torch.Size([1, 42])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 91]) torch.Size([1, 91])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 80]) torch.Size([1, 80])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 75]) torch.Size([1, 75])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 83]) torch.Size([1, 83])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 76]) torch.Size([1, 76])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 88]) torch.Size([1, 88])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 73]) torch.Size([1, 73])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 89]) torch.Size([1, 89])\n",
      "torch.Size([1, 72]) torch.Size([1, 72])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 70]) torch.Size([1, 70])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 73]) torch.Size([1, 73])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 75]) torch.Size([1, 75])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 70]) torch.Size([1, 70])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 78]) torch.Size([1, 78])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 72]) torch.Size([1, 72])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 47]) torch.Size([1, 47])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 76]) torch.Size([1, 76])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 42]) torch.Size([1, 42])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 71]) torch.Size([1, 71])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 74]) torch.Size([1, 74])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 65]) torch.Size([1, 65])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 48]) torch.Size([1, 48])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 53]) torch.Size([1, 53])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 67]) torch.Size([1, 67])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 45]) torch.Size([1, 45])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 66]) torch.Size([1, 66])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 61]) torch.Size([1, 61])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 76]) torch.Size([1, 76])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 80]) torch.Size([1, 80])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n",
      "torch.Size([1, 64]) torch.Size([1, 64])\n",
      "torch.Size([1, 51]) torch.Size([1, 51])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 83]) torch.Size([1, 83])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 59]) torch.Size([1, 59])\n",
      "torch.Size([1, 49]) torch.Size([1, 49])\n",
      "torch.Size([1, 54]) torch.Size([1, 54])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 58]) torch.Size([1, 58])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 44]) torch.Size([1, 44])\n",
      "torch.Size([1, 60]) torch.Size([1, 60])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 74]) torch.Size([1, 74])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 55]) torch.Size([1, 55])\n",
      "torch.Size([1, 74]) torch.Size([1, 74])\n",
      "torch.Size([1, 46]) torch.Size([1, 46])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 80]) torch.Size([1, 80])\n",
      "torch.Size([1, 57]) torch.Size([1, 57])\n",
      "torch.Size([1, 68]) torch.Size([1, 68])\n",
      "torch.Size([1, 62]) torch.Size([1, 62])\n",
      "torch.Size([1, 52]) torch.Size([1, 52])\n",
      "torch.Size([1, 69]) torch.Size([1, 69])\n",
      "torch.Size([1, 56]) torch.Size([1, 56])\n",
      "torch.Size([1, 63]) torch.Size([1, 63])\n",
      "torch.Size([1, 43]) torch.Size([1, 43])\n",
      "torch.Size([1, 81]) torch.Size([1, 81])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872ce4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705,    40,   716,  3772,\n",
      "            6,   656,  4141,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  4141, 11059,   286,   705,    40,   716,  3772,     6,   318,\n",
      "          705, 40932,   424,   271,   339,   495,  2821,     6,   357,   361,\n",
      "          262, 10834,   318,  4257,     8,   393,   705, 40932,   424,   271,\n",
      "          339,   495,  1904,     6,   357,   361,   262, 10834,   318,  4048,\n",
      "          737], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ec23776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198,  8291, 17660,   705,    40,   716,  3772,     6,\n",
      "          656,  4141,    13,   198,   198, 21017, 18261,    25,   198,   464,\n",
      "         4141, 11059,   286,   705,    40,   716,  3772,     6,   318,   705,\n",
      "        40932,   424,   271,   339,   495,  2821,     6,   357,   361,   262,\n",
      "        10834,   318,  4257,     8,   393,   705, 40932,   424,   271,   339,\n",
      "          495,  1904,     6,   357,   361,   262, 10834,   318,  4048,   737,\n",
      "        50256], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ae276a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 20:49:14.641378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765811954.660965  134547 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765811954.667199  134547 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1765811954.684334  134547 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765811954.684371  134547 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765811954.684373  134547 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765811954.684375  134547 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-15 20:49:14.689545: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b128f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac23a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    token_ids_to_text,\n",
    "    text_to_token_ids\n",
    ")\n",
    "\n",
    "# token_ids = generate(\n",
    "#     model=model,\n",
    "#     idx=text_to_token_ids(input_text, tokenizer),\n",
    "#     max_new_tokens=35,\n",
    "#     context_size=BASE_CONFIG[\"context_length\"],\n",
    "#     eos_id=50256\n",
    "# )\n",
    "# generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b56863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_text = (\n",
    "#     generated_text[len(input_text):]\n",
    "#     .replace(\"### Response:\", \"\")\n",
    "#     .strip()\n",
    "# )\n",
    "# print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7278dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple,\n",
    "    train_model_simple_with_grad_accum\n",
    ")\n",
    "\n",
    "# model.to(device)\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "#     val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "# print(\"Training loss:\", train_loss)\n",
    "# print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89cfb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\")\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# # optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "# optimizer = torch.optim.AdamW(\n",
    "#     model.parameters(), \n",
    "#     lr=0.00005 / 4,  # Divide by accumulation_steps\n",
    "#     weight_decay=0.1\n",
    "# )\n",
    "\n",
    "# num_epochs = 2\n",
    "\n",
    "# train_losses, val_losses, tokens_seen = train_model_simple_with_grad_accum(\n",
    "#     model, train_loader, val_loader, optimizer, device,\n",
    "#     num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "#     start_context=format_input(val_data[0]), tokenizer=tokenizer, accumulation_steps=4\n",
    "# )\n",
    "\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ec3db25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MEMORY REQUIREMENTS ESTIMATE\n",
      "============================================================\n",
      "model_parameters........................ 1.51 GB\n",
      "gradients............................... 1.51 GB\n",
      "activations_estimate.................... 0.00 GB\n",
      "optimizer_standard...................... 3.03 GB\n",
      "optimizer_8bit.......................... 0.76 GB\n",
      "total_standard.......................... 6.06 GB\n",
      "total_8bit.............................. 3.79 GB\n",
      "\n",
      "============================================================\n",
      "TRAINING CONFIGURATION\n",
      "============================================================\n",
      "Model: GPT-2 355M\n",
      "Strategy: 8-bit Adam + Gradient Checkpointing + Mixed Precision\n",
      "Gradient Accumulation Steps: 8 (effective batch size)\n",
      "Learning Rate: 0.00005 / 8 = 0.0000063\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "GPU: NVIDIA GeForce RTX 2060\n",
      "Total Memory: 5.61 GB\n",
      "Accumulation Steps: 8\n",
      "Effective Batch Size: 8\n",
      "============================================================\n",
      "\n",
      " Gradient checkpointing enabled\n",
      " Using 8-bit AdamW optimizer (75% memory reduction)\n",
      "\n",
      "============================================================\n",
      "Epoch 1/2\n",
      "============================================================\n",
      "Ep 1 (Step 000000): Train loss 3.900, Val loss 3.867\n",
      "Ep 1 (Step 000005): Train loss 2.897, Val loss 2.947\n",
      "Ep 1 (Step 000010): Train loss 2.242, Val loss 2.460\n",
      "Ep 1 (Step 000015): Train loss 1.965, Val loss 2.045\n",
      "Ep 1 (Step 000020): Train loss 1.226, Val loss 1.707\n",
      "Ep 1 (Step 000025): Train loss 1.028, Val loss 1.366\n",
      "Ep 1 (Step 000030): Train loss 0.965, Val loss 1.201\n",
      "Ep 1 (Step 000035): Train loss 1.085, Val loss 1.142\n",
      "Ep 1 (Step 000040): Train loss 1.013, Val loss 1.115\n",
      "Ep 1 (Step 000045): Train loss 0.618, Val loss 1.090\n",
      "Ep 1 (Step 000050): Train loss 0.844, Val loss 1.056\n",
      "Ep 1 (Step 000055): Train loss 0.938, Val loss 1.014\n",
      "Ep 1 (Step 000060): Train loss 0.993, Val loss 1.008\n",
      "Ep 1 (Step 000065): Train loss 0.890, Val loss 0.993\n",
      "Ep 1 (Step 000070): Train loss 0.494, Val loss 0.985\n",
      "Ep 1 (Step 000075): Train loss 0.573, Val loss 0.973\n",
      "Ep 1 (Step 000080): Train loss 0.923, Val loss 0.970\n",
      "Ep 1 (Step 000085): Train loss 0.670, Val loss 0.976\n",
      "Ep 1 (Step 000090): Train loss 0.785, Val loss 0.957\n",
      "Ep 1 (Step 000095): Train loss 0.616, Val loss 0.940\n",
      "Ep 1 (Step 000100): Train loss 0.748, Val loss 0.927\n",
      "Ep 1 (Step 000105): Train loss 0.594, Val loss 0.929\n",
      "Ep 1 (Step 000110): Train loss 0.932, Val loss 0.927\n",
      "Ep 1 (Step 000115): Train loss 0.736, Val loss 0.926\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The\n",
      "\n",
      "============================================================\n",
      "Epoch 2/2\n",
      "============================================================\n",
      "Ep 2 (Step 000000): Train loss 0.688, Val loss 0.920\n",
      "Ep 2 (Step 000005): Train loss 0.777, Val loss 0.906\n",
      "Ep 2 (Step 000010): Train loss 0.957, Val loss 0.906\n",
      "Ep 2 (Step 000015): Train loss 0.642, Val loss 0.895\n",
      "Ep 2 (Step 000020): Train loss 0.667, Val loss 0.900\n",
      "Ep 2 (Step 000025): Train loss 0.729, Val loss 0.899\n",
      "Ep 2 (Step 000030): Train loss 0.560, Val loss 0.892\n",
      "Ep 2 (Step 000035): Train loss 0.600, Val loss 0.883\n",
      "Ep 2 (Step 000040): Train loss 0.499, Val loss 0.879\n",
      "Ep 2 (Step 000045): Train loss 0.652, Val loss 0.865\n",
      "Ep 2 (Step 000050): Train loss 0.572, Val loss 0.862\n",
      "Ep 2 (Step 000055): Train loss 0.494, Val loss 0.865\n",
      "Ep 2 (Step 000060): Train loss 0.732, Val loss 0.858\n",
      "Ep 2 (Step 000065): Train loss 0.816, Val loss 0.849\n",
      "Ep 2 (Step 000070): Train loss 0.625, Val loss 0.840\n",
      "Ep 2 (Step 000075): Train loss 0.596, Val loss 0.831\n",
      "Ep 2 (Step 000080): Train loss 0.581, Val loss 0.823\n",
      "Ep 2 (Step 000085): Train loss 0.555, Val loss 0.817\n",
      "Ep 2 (Step 000090): Train loss 0.539, Val loss 0.805\n",
      "Ep 2 (Step 000095): Train loss 0.419, Val loss 0.793\n",
      "Ep 2 (Step 000100): Train loss 0.595, Val loss 0.791\n",
      "Ep 2 (Step 000105): Train loss 0.494, Val loss 0.794\n",
      "Ep 2 (Step 000110): Train loss 0.660, Val loss 0.801\n",
      "Ep 2 (Step 000115): Train loss 0.858, Val loss 0.814\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United States? \n",
      "\n",
      "============================================================\n",
      " Training completed in 8.42 minutes\n",
      "============================================================\n",
      "\n",
      "\n",
      "GPU Memory:\n",
      "  Allocated: 1.63 GB / 5.61 GB (29.0%)\n",
      "  Reserved:  2.90 GB / 5.61 GB (51.7%)\n",
      "  Free:      3.98 GB\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MEMORY-EFFICIENT TRAINING FOR GPT-2 355M\n",
    "# ============================================================================\n",
    "\n",
    "# First, install bitsandbytes for 8-bit optimizer (75% memory reduction)\n",
    "# Run this in terminal: pip install bitsandbytes\n",
    "\n",
    "from memory_efficient_trainer import (\n",
    "    train_memory_efficient,\n",
    "    estimate_memory_requirements,\n",
    "    print_memory_usage\n",
    ")\n",
    "import time\n",
    "\n",
    "# Clear memory before training\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Estimate memory requirements\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEMORY REQUIREMENTS ESTIMATE\")\n",
    "print(\"=\"*60)\n",
    "memory_est = estimate_memory_requirements(model, batch_size=1, seq_length=1024)\n",
    "for key, value in memory_est.items():\n",
    "    print(f\"{key:.<40} {value:.2f} GB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: GPT-2 355M\")\n",
    "print(f\"Strategy: 8-bit Adam + Gradient Checkpointing + Mixed Precision\")\n",
    "print(f\"Gradient Accumulation Steps: 8 (effective batch size)\")\n",
    "print(f\"Learning Rate: 0.00005 / 8 = {0.00005/8:.7f}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Train with memory optimizations\n",
    "train_losses, val_losses, tokens_seen = train_memory_efficient(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    num_epochs=2,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=format_input(val_data[0]),\n",
    "    tokenizer=tokenizer,\n",
    "    learning_rate=0.00005,\n",
    "    accumulation_steps=8,  # Increase if still getting OOM\n",
    "    use_8bit_optimizer=True,  # Set to False if bitsandbytes not available\n",
    "    use_gradient_checkpointing=True\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\" Training completed in {execution_time_minutes:.2f} minutes\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Print final memory usage\n",
    "print_memory_usage()\n",
    "\n",
    "# Plot losses\n",
    "from previous_chapters import plot_losses\n",
    "epochs_tensor = torch.linspace(0, 2, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75e3e4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is very fast.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Sir Walter Scott.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e864e406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [01:42<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cb74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
