{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32a1198",
   "metadata": {},
   "source": [
    "# Pre-Training with loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2b1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from previous_chapters import GPTModel, generate_text_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff9d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads  \n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14622576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d640d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada85b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b772e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "655bf1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84832bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0a0d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09fc060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b23489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "712084e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d15c1103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64fbb252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61686321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    text_data = response.text\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "455a7980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea5eccda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c36acb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef1b00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b24e5563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd82881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "158ed068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38a8b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18fccaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52fdeed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583266364204\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74dcea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a41e8683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.016, Val loss 10.126\n",
      "Ep 1 (Step 000005): Train loss 8.206, Val loss 8.260\n",
      "Every effort moves you, the,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000010): Train loss 6.807, Val loss 7.060\n",
      "Ep 2 (Step 000015): Train loss 6.085, Val loss 6.586\n",
      "Every effort moves you, the, the, the, the, the, the, the,, the, the,,, the,, the,, the,,, the,,, the, the,, the,, the,,, the,\n",
      "Ep 3 (Step 000020): Train loss 14.529, Val loss 14.984\n",
      "Ep 3 (Step 000025): Train loss 5.445, Val loss 6.420\n",
      "Every effort moves you, and a.                                              \n",
      "Ep 4 (Step 000030): Train loss 4.972, Val loss 6.383\n",
      "Ep 4 (Step 000035): Train loss 4.857, Val loss 6.275\n",
      "Every effort moves you, and, and a, and--, and a, and his a, and, and I was, and I had a, and in the picture, and I had to the picture, and, and, and a, and I had to\n",
      "Ep 5 (Step 000040): Train loss 4.265, Val loss 6.193\n",
      "Every effort moves you know the                          \"I, I can a a he had the picture.  \"I had the Riv he was his\n",
      "Ep 6 (Step 000045): Train loss 4.011, Val loss 6.173\n",
      "Ep 6 (Step 000050): Train loss 3.628, Val loss 6.164\n",
      "Every effort moves you know the      \"--as a good-c, and he was no I can to me to the donkey, and I had been the fact-c, and his painting, and up and down the donkey, and in\n",
      "Ep 7 (Step 000055): Train loss 2.991, Val loss 6.150\n",
      "Ep 7 (Step 000060): Train loss 2.572, Val loss 6.160\n",
      "Every effort moves you know the inevitable garlanded to have to the picture--as such--had not to the picture, with the fact of the picture to the picture, with a little to have to the picture. \"I was \"There were, I was\n",
      "Ep 8 (Step 000065): Train loss 2.256, Val loss 6.134\n",
      "Ep 8 (Step 000070): Train loss 1.736, Val loss 6.153\n",
      "Every effort moves you know,\" was not that my hostess was--I had a little of a flash that he was a little to me to have to see a smile of his pictures.  \"--I had I had been the man of the hour. \n",
      "Ep 9 (Step 000075): Train loss 1.576, Val loss 6.203\n",
      "Ep 9 (Step 000080): Train loss 1.052, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the picture. The mere outline of the frame called up all Gisburn's past!    \"--it was back the window-curtains, I had the _jardiniere_ full of\n",
      "Ep 10 (Step 000085): Train loss 0.878, Val loss 6.315\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  \"I turned, and threw back his glory, he had dropped his painting, a _jardiniere_ full of\n",
      "Training completed in 0.47 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbfe0daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    # plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd07ba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NEW: use CPU here as inference is cheap with \n",
    "# this model and to ensure readers get same results in the\n",
    "# remaining sections of this book\n",
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260a95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
